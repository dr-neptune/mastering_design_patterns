#+TITLE: Microservices and Patterns for the Cloud

In this chapter, we discuss the following patterns:

- The Retry Pattern
- The Circuit Breaker Pattern
- The Cache-Aside Pattern
- The Throttling Pattern

* Use Cases

We can use a microservice architecture-based design every time we are building an application that has at least one of the following characteristics:

- There is a requirement to support different clients, i.e. desktop and mobile
- There is an API for third parties to consume
- We have to communicate with other applications using messaging
- We have to serve requests by accessing a database, communicating with other systems, and returning the right type of response (JSON, HTML, XML, others)
- There are logical components corresponding to different functional areas of the application

* Implementation

We will discuss 2 small examples of service implementation:

- A service that can return a list of people names when called
- A service that calls the first one and appends the names obtained as a result to a CSV file on disk

#+BEGIN_SRC python :tangle service_first.py
from nameko.rpc import rpc
from faker import Faker

fake = Faker()


class PeopleListService:
    name = "peoplelist"

    @rpc
    def populate(self, number=20):
        names = []
        for _ in range(0, number):
            n = fake.name()
            names.append(n)
        return names
#+END_SRC


#+BEGIN_SRC python :tangle test_service_first.py
from nameko.testing.services import worker_factory
from service_first import PeopleListService


def test_people():
    service_worker = worker_factory(PeopleListService)
    result = service_worker.populate()
    for name in result:
        print(name)


if __name__ == '__main__':
    test_people()
#+END_SRC


* A Second Example

We will reuse the idea of a toy service that helps produce a list of people.
Now we want the first name, last name, and the address of people. We will have
a second service that depends on the first one to call it in order to get a list
of people and then save that list on disk. Since our service B depends on service A
we will use the RpcProxy class.

#+BEGIN_SRC python :tangle service_second.py
from nameko.rpc import rpc, RpcProxy
from faker import Faker
import csv

fake = Faker()

class PeopleListService:
    name = "peoplelist"

    @rpc
    def populate(self, number=20):
        persons = []
        for _ in range(0, number):
            p = {'firstname': fake.first_name(),
                 'lastname': fake.last_name(),
                 'address': fake.address()}
            persons.append(p)
        return persons

class PeopleDataPersistenceService:
    name = "people_data_persistence"
    peoplelist_rpc = RpcProxy("peoplelist")

    @rpc
    def save(self, filename):
        persons = self.peoplelist_rpc.populate(number=25)

        with open(filename, "a", newline="") as csv_file:
            fieldnames = ["firstname", "lastname", "address"]
            writer = csv.DictWriter(csv_file,
                                    fieldnames=fieldnames,
                                    delimiter=";")
            for p in persons:
                writer.writerow(p)

        return f"Saved data for {len(persons)} new people"
#+END_SRC


#+BEGIN_SRC python :tangle test_service_second.py
from nameko.testing.services import worker_factory
from nameko.standalone.rpc import ClusterRpcProxy
from service_second import PeopleDataPersistenceService

config = {"AMQP_URI": "pyamqp://guest:guest@127.0.0.1"}

def test_peopledata_persist():
    with ClusterRpcProxy(config) as cluster_rpc:
        out = cluster_rpc.people_data_persistence.save.call_async("people.csv")
        print(out.result())

if __name__ == '__main__':
    test_peopledata_persist()
#+END_SRC

* The Retry Pattern

Parts of a cloud-native application may experience what is called transient fauls or failures, meaning some mini issues can look like bugs, but they are not due to your application itself. Instead they are due to constraints outside of your control such as the networking or the external server/service performance. As a result, the application may dysfunction and hang. The answer to this risk is to put in place some retry logic.

The retrying approach is recommended to alleviate the impact of identified transient failrues while communicating with an external component or service due to network failure or server overload. It is not recommended for handling failures such as internal exceptions caused by errors in the application logic itself. We also must address the way the server responds. If the application experiences frequent busy faults, then its a sign that the service being accessed has a scaling issue that should be addressed.

* A First Example

Suppose we want to write and update a file using two different programs. Instead of creating two scripts, we can instead create a single script that can be called by an argument to indicate what we want to do: create the file, or update it.

#+BEGIN_SRC python :tangle retry_1.py
import time
import sys
import os

def create_file(filename, after_delay=5):
    time.sleep(after_delay)

    with open(filename, "w") as f:
        f.write("A file creation test")

def append_data_to_file(filename):
    if os.path.exists(filename):
        with open(filename, "a") as f:
            f.write("\tUpdating the file")
    else:
        raise OSError

FILENAME = 'file1.txt'

if __name__ == '__main__':
    args = sys.argv

    if args[1] == "create":
        create_file(FILENAME)
        print(f"Created file '{FILENAME}'")
    elif args[1] == "update":
        while True:
            try:
                append_data_to_file(FILENAME)
                print("Success! We are done!")
                break
            except OSError as e:
                print("Error.\tTry Again!")
#+END_SRC

* A Second Example

Using the retrying library

#+BEGIN_SRC python :tangle retry_2.py
import time
import sys
import os
from retrying import retry


def create_file(filename, after_delay=5):
    time.sleep(after_delay)

    with open(filename, "w") as f:
        f.write("A file creation test")

@retry
def append_data_to_file(filename):
    if os.path.exists(filename):
        print("Got the file -- let's proceed!")
        with open(filename, "a") as f:
            f.write("\tUpdating the file")
        return "okie dokie, artichokey"
    else:
        print("Error: Missing File. Retrying")
        raise OSError

FILENAME = 'file2.txt'

if __name__ == '__main__':
    args = sys.argv

    if args[1] == "create":
        create_file(FILENAME)
        print(f"Created file '{FILENAME}'")
    elif args[1] == "update":
        while True:
            out = append_data_to_file(FILENAME)
            if out == "okie dokie, artichokey":
                print("Success! We are done!")
                break
#+END_SRC

* The Circuit Breaker Pattern

With the circuit breaker pattern, you wrap a fragile function call (or an integration point with an external service) in a special (circuit breaker) object, which monitors for failures. Once the failures reach a certain threshold, the circuit breaker trips, and all further calls to the circuit breaker return with an error, without the protected call being made at all.

We use this pattern when we need a component to be fault-tolerant to long-lasting failures when communicating with an external component, service, or resource.

* Implementation

Let's say we wish to use a circuit breaker on a flaky function (for example, fragile due to the networking environment it depends on.)

#+BEGIN_SRC python :tangle circuit.py
import random
import pybreaker
from time import sleep
from datetime import datetime

breaker = pybreaker.CircuitBreaker(fail_max=2, reset_timeout=5)

@breaker
def fragile_function():
    if not random.choice([True, False]):
        print(" / OK\n", end="")
    else:
        print(" / FAIL\n", end="")
        raise Exception("This is a sample exception\n")


if __name__ == '__main__':

    while True:
        print(datetime.now().strftime("%Y-%m-%d %H:%M:%S"), end="")
        try:
            fragile_function()
        except Exception as e:
            print(" / {} {}".format(type(e), e), end="")
        finally:
            sleep(1)
#+END_SRC

* The Cache-Aside Pattern

In situations where data is more frequently read than updated, applications use a cache to optimize repeated access to information stored in a database or data store. In some systems, the caching mechanism is built in and works automatically. When this is not the case, we have to implement it in the app ourselves

We perform the following:

Load data on demand into a cache from a data store, as an attempt to improve performance, while maintaining consistency between data held in the cache and the data in the underlying data store.

The Cache-aside pattern is useful for data that doesn't change often, and for data storage that doesn't depend on the consistency of a set of
entries in the storage (multiple keys).

* Implementation

*Case 1*: We want to fetch a data item: return the item from cache if found in it. If not found in cache, read the data from the database. Put the read item in the cache and return it.

*Case 2*: When we want to update a data item: write the item in the database and remove the corresponding entry from the cache.

We will implement a database of quotes from which the user can ask to retrieve some quotes via an application. Our focus will be on implementing case 1.

Instead of using a system with real caching capabilities like memcached or redis, we will use a CSV file to emulate how data is loaded to and read from the cache on demand.

#+BEGIN_SRC python :tangle populate_db.py
import sys
import sqlite3
import csv
from random import randint
from faker import Faker


fake = Faker()


def setup_db():
    try:
        db = sqlite3.connect("data/quotes.sqlite3")

        # get a cursor object
        cursor = db.cursor()
        cursor.execute("""
        CREATE TABLE quotes(id INTEGER PRIMARY KEY, text TEXT)
        """)
        db.commit()
    except Exception as e:
        print(e)
    finally:
        db.close()


def add_quotes(quotes_list):
    quotes = []
    try:
        db = sqlite3.connect("data/quotes.sqlite3")
        cursor = db.cursor()
        quotes = []
        for quote_text in quotes_list:
            quote_id = randint(1, 100)
            quote = (quote_id, quote_text)
            try:
                cursor.execute("""INSERT INTO quotes(id, text) VALUES(?,?)""", quote)
                quotes.append(quote)
            except Exception as e:
                print(f"Error with quote id {quote_id}: {e}")
        db.commit()
    except Exception as e:
        print(e)
    finally:
        db.close()
    return quotes


def main():
    args = sys.argv

    # initialize the database
    if args[1] == "init":
        setup_db()
    # update the database with new quotes. Write to "db" and display on screen
    elif args[1] == "update_db_and_cache":
        quotes_list = [fake.sentence() for _ in range(1, 11)]
        quotes = add_quotes(quotes_list)
        print("New (fake) quotes added to the database")
        for q in quotes:
            print(f"Added to DB:\t{q}")
        # populate the cache with this content
        with open("data/quotes_cache.csv", "a", newline="") as csv_file:
            writer = csv.DictWriter(csv_file,
                                    fieldnames=["id", "text"],
                                    delimiter=";")
            for q in quotes:
                print(f"Adding '{q[1]}' to cache")
                writer.writerow({'id': str(q[0]),
                                 'text': q[1]})
    # generate quotes, and display on screen
    elif args[1] == "update_db_only":
        quotes_list = [fake.sentence() for _ in range(1, 11)]
        quotes = add_quotes(quotes_list)
        print("New (fake) quotes added to the database ONLY:")
        for q in quotes:
            print(f"Added to DB: {q}")


if __name__ == '__main__':
    main()
#+END_SRC

#+BEGIN_SRC python :tangle cache_aside.py
import sys
import sqlite3
import csv


cache_key_prefix = "quote"


class QuoteCache:
    def __init__(self, filename=""):
        self.filename = filename

    def get(self, key):
        with open(self.filename) as csv_file:
            items = csv.reader(csv_file, delimiter=";")
            for item in items:
                if item[0] == key.split(".")[1]:
                    return item[1]

    def set(self, key, quote):
        existing = []
        with open(self.filename) as csv_file:
            items = csv.reader(csv_file, delimiter=";")
            existing = [cache_key_prefix + "." + item[0] for item in items]

        if key in existing:
            print("This key already exists")
        else:
            # save the new data
            with open(self.filename, "a", newline="") as csv_file:
                writer = csv.DictWriter(csv_file,
                                        fieldnames=["id", "text"],
                                        delimiter=";")
                writer.writerow({"id": key.split(".")[1],
                                 "text": quote})


cache = QuoteCache("data/quotes_cache.csv")

def get_quote(quote_id):
    quote = cache.get(f"quote.{quote_id}")
    out = ""
    if quote is None:
        try:
            db = sqlite3.connect("data/quotes.sqlite3")
            cursor = db.cursor()
            cursor.execute(f"SELECT text FROM quotes WHERE id = {quote_id}")
            for row in cursor:
                quote = row[0]
            print(f"Got '{quote}' from DB")
        except Exception as e:
            print(e)
        finally:
            # close the db connection
            db.close()

        # add it to the cache
        key = f"{cache_key_prefix}.{quote_id}"
        cache.set(key, quote)
    else:
        out = f"{quote} (FROM CACHE, with key 'quote.{quote_id}')"
    return out


if __name__ == '__main__':
    args = sys.argv

    if args[1] == "fetch":
        while True:
            quote_id = input("Enter the ID of the quote: ")
            q = get_quote(quote_id)
            if q:
                print(q)
#+END_SRC

* Throttling

Throttling is limiting the number of a requests a user can send to a given web service in a given amount of time, in order to protect the
resources of the service from being overused by some users.

In practice, we may implement the following rules:
- Limit the number of total requests to an API as n/day
- Limit the number of total requests to an API as n/day from a given IP address or from a given country/region
- Limit the number of reads or writes for authenticated users

* Implementation

There are different types of throttling, among which rate-limit, IP-level limit, and concurrent connections limiit are some.
We will focus on the first one here. We will make an example of rate-limit throttling using a Flask app.

#+BEGIN_SRC python :tangle flask_throttling.py
from flask import Flask
from flask_limiter import Limiter
from flask_limiter.util import get_remote_address


app = Flask(__name__)


# define the limiter instance
limiter = Limiter(
    app,
    key_func=get_remote_address,
    default_limits=["100 per day", "10 per hour"]
)


# now we can define a limited route
@app.route("/limited")
def limited_api():
    return "Welcome to our API!"


@app.route("/more_limited")
@limiter.limit("2/minute")
def more_limited_api():
    return "Welcome to our expensive, thus very limited, API!"


@app.route("/super_limited")
@limiter.limit("1/minute")
def super_limited_api():
    return "This is getting out of hand"


if __name__ == '__main__':
    app.run(debug=True)
#+END_SRC
